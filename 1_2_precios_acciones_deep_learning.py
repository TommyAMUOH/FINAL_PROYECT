# -*- coding: utf-8 -*-
"""1_2_Precios_Acciones_Deep_Learning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DzwWyW5NFSHOTK4qziexM6_osl7h1EUK
"""

from google.colab import drive
drive.mount('/content/drive')

import math
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

import tensorflow as tf
from sklearn.metrics import mean_squared_error, mean_absolute_error

import warnings
warnings.filterwarnings('ignore')

AAPL = pd.read_csv("/content/drive/MyDrive/Database/Pre_Processed_AAPL.csv") #Apple
TSLA = pd.read_csv("/content/drive/MyDrive/Database/Pre_Processed_TSLA.csv") #Tesla
GOOG = pd.read_csv("/content/drive/MyDrive/Database/Pre_Processed_GOOG.csv") #Google
MSFT = pd.read_csv("/content/drive/MyDrive/Database/Pre_Processed_MSFT.csv") #Microsoft
AMZN = pd.read_csv("/content/drive/MyDrive/Database/Pre_Processed_AMZN.csv") #Amazon

"""### Preprocesamiento de datos"""

def Dataset(Data, Date):

  Train_Data = Data['Adj. Close'][Data['Date'] < Date].to_numpy()
  Data_Train = []
  Data_Train_X = []
  Data_Train_Y = []
  for i in range(0, len(Train_Data), 5):
    try:
      Data_Train.append(Train_Data[i : i + 5])
    except:
      pass

  if len(Data_Train[-1]) < 5:
    Data_Train.pop(-1)

  Data_Train_X = Data_Train[0 : -1]
  Data_Train_X = np.array(Data_Train_X)
  Data_Train_X = Data_Train_X.reshape((-1, 5, 1))
  Data_Train_Y = Data_Train[1 : len(Data_Train)]
  Data_Train_Y = np.array(Data_Train_Y)
  Data_Train_Y = Data_Train_Y.reshape((-1, 5, 1))


  Test_Data = Data['Adj. Close'][Data['Date'] >= Date].to_numpy()
  Data_Test = []
  Data_Test_X = []
  Data_Test_Y = []
  for i in range(0, len(Test_Data), 5):
    try:
      Data_Test.append(Test_Data[i : i + 5])
    except:
      pass

  if len(Data_Test[-1]) < 5:
    Data_Test.pop(-1)

  Data_Test_X = Data_Test[0 : -1]
  Data_Test_X = np.array(Data_Test_X)
  Data_Test_X = Data_Test_X.reshape((-1, 5, 1))
  Data_Test_Y = Data_Test[1 : len(Data_Test)]
  Data_Test_Y = np.array(Data_Test_Y)
  Data_Test_Y = Data_Test_Y.reshape((-1, 5, 1))

  return Data_Train_X, Data_Train_Y, Data_Test_X, Data_Test_Y

"""### Modelo basado en Deep Learning"""

def Model():
  model = tf.keras.models.Sequential([
                                      tf.keras.layers.LSTM(200, input_shape = (5, 1), activation = tf.nn.leaky_relu, return_sequences = True),
                                      tf.keras.layers.LSTM(200, activation = tf.nn.leaky_relu),
                                      tf.keras.layers.Dense(200, activation = tf.nn.leaky_relu),
                                      tf.keras.layers.Dense(100, activation = tf.nn.leaky_relu),
                                      tf.keras.layers.Dense(50, activation = tf.nn.leaky_relu),
                                      tf.keras.layers.Dense(5, activation = tf.nn.leaky_relu)
                                      ])
  return model

model = Model()

tf.keras.utils.plot_model(model, show_shapes=True)

model.summary()

"""### Tasa de aprendizaje personalizada"""

def scheduler(epoch):

  if epoch <= 150:
    lrate = (10 ** -5) * (epoch / 150)
  elif epoch <= 400:
    initial_lrate = (10 ** -5)
    k = 0.01
    lrate = initial_lrate * math.exp(-k * (epoch - 150))
  else:
    lrate = (10 ** -6)

  return lrate

epochs = [i for i in range(1, 1001, 1)]
lrate = [scheduler(i) for i in range(1, 1001, 1)]
plt.plot(epochs, lrate)

callback = tf.keras.callbacks.LearningRateScheduler(scheduler)

"""#Apple: Base de datos de acciones"""

AAPL.head()

AAPL.info()

# Change Dtype of Date column
AAPL["Date"] = pd.to_datetime(AAPL["Date"])

"""###Split the Data into Training and Test set
    Training Period: 2015-01-02 - 2020-09-30

    Testing Period:  2020-10-01 - 2021-02-26
"""

AAPL_Date = '2020-10-01'
AAPL_Train_X, AAPL_Train_Y, AAPL_Test_X, AAPL_Test_Y = Dataset(AAPL, AAPL_Date)

"""### Model Fitting"""

AAPL_Model = Model()

AAPL_Model.compile(optimizer = tf.keras.optimizers.Adam(), loss = 'mse', metrics = tf.keras.metrics.RootMeanSquaredError())

AAPL_hist = AAPL_Model.fit(AAPL_Train_X, AAPL_Train_Y, epochs = 1000, validation_data = (AAPL_Test_X, AAPL_Test_Y), callbacks=[callback])

history_dict = AAPL_hist.history

loss = history_dict["loss"]
root_mean_squared_error = history_dict["root_mean_squared_error"]
val_loss = history_dict["val_loss"]
val_root_mean_squared_error = history_dict["val_root_mean_squared_error"]

epochs = range(1, len(loss) + 1)

fig, (ax1, ax2) = plt.subplots(1, 2)

fig.set_figheight(5)
fig.set_figwidth(15)

ax1.plot(epochs, loss, label = 'Training Loss')
ax1.plot(epochs, val_loss, label = 'Validation Loss')
ax1.set(xlabel = "Epochs", ylabel = "Loss")
ax1.legend()

ax2.plot(epochs, root_mean_squared_error, label = "Training Root Mean Squared Error")
ax2.plot(epochs, val_root_mean_squared_error, label = "Validation Root Mean Squared Error")
ax2.set(xlabel = "Epochs", ylabel = "Loss")
ax2.legend()

plt.show()

"""### Predicting the closing stock price of Apple"""

AAPL_prediction = AAPL_Model.predict(AAPL_Test_X)

plt.figure(figsize=(20, 5))
plt.plot(AAPL['Date'][AAPL['Date'] < '2020-10-12'], AAPL['Adj. Close'][AAPL['Date'] < '2020-10-12'], label = 'Training')
plt.plot(AAPL['Date'][AAPL['Date'] >= '2020-10-09'], AAPL['Adj. Close'][AAPL['Date'] >= '2020-10-09'], label = 'Testing')
plt.plot(AAPL['Date'][AAPL['Date'] >= '2020-10-12'], AAPL_prediction.reshape(-1), label = 'Predictions')
plt.xlabel('Time')
plt.ylabel('Closing Price')
plt.legend(loc = 'best')

rmse = math.sqrt(mean_squared_error(AAPL_Test_Y.reshape(-1, 5), AAPL_prediction))
mape = np.mean(np.abs(AAPL_prediction - AAPL_Test_Y.reshape(-1, 5))/np.abs(AAPL_Test_Y.reshape(-1, 5)))
print(f'RMSE: {rmse}')
print(f'MAPE: {mape}')

"""#Tesla: Base de datos de acciones"""

TSLA.head()

TSLA.info()

# Change Dtype of Date column
TSLA["Date"] = pd.to_datetime(TSLA["Date"])

"""###Dividir los datos en conjunto de entrenamiento y prueba
    Periodo para partición de entrenamiento: 2015-01-02 - 2020-09-30

    Periodo para partición de testing: 2020-10-01 - 2021-02-26
"""

TSLA_Date = '2020-10-01'
TSLA_Train_X, TSLA_Train_Y, TSLA_Test_X, TSLA_Test_Y = Dataset(TSLA, TSLA_Date)

"""### Entrenamiento del modelo"""

TSLA_Model = Model()

TSLA_Model.compile(optimizer = tf.keras.optimizers.Adam(), loss = 'mse', metrics = tf.keras.metrics.RootMeanSquaredError())

TSLA_hist = TSLA_Model.fit(TSLA_Train_X, TSLA_Train_Y, epochs = 200, validation_data = (TSLA_Test_X, TSLA_Test_Y), callbacks=[callback])

history_dict = TSLA_hist.history

loss = history_dict["loss"]
root_mean_squared_error = history_dict["root_mean_squared_error"]
val_loss = history_dict["val_loss"]
val_root_mean_squared_error = history_dict["val_root_mean_squared_error"]

epochs = range(1, len(loss) + 1)

fig, (ax1, ax2) = plt.subplots(1, 2)

fig.set_figheight(5)
fig.set_figwidth(15)

ax1.plot(epochs, loss, label = "Training Loss")
ax1.plot(epochs, val_loss, label = "Validation Loss")
ax1.set(xlabel = "Epochs", ylabel = "Loss")
ax1.legend()

ax2.plot(epochs, root_mean_squared_error, label = "Training Root Mean Squared Error")
ax2.plot(epochs, val_root_mean_squared_error, label = "Validation Root Mean Squared Error")
ax2.set(xlabel = "Epochs", ylabel = "Loss")
ax2.legend()

plt.show()

"""### Predecir el precio de cierre de las acciones de Tesla"""

TSLA_prediction = TSLA_Model.predict(TSLA_Test_X)

plt.figure(figsize=(10, 5))
plt.plot(TSLA['Date'][TSLA['Date'] < '2020-10-12'], TSLA['Adj. Close'][TSLA['Date'] < '2020-10-12'], label = 'Training')
plt.plot(TSLA['Date'][TSLA['Date'] >= '2020-10-09'], TSLA['Adj. Close'][TSLA['Date'] >= '2020-10-09'], label = 'Testing')
plt.plot(TSLA['Date'][TSLA['Date'] >= '2020-10-12'], TSLA_prediction.reshape(-1), label = 'Predictions')
plt.xlabel('Time')
plt.ylabel('Closing Price')
plt.legend(loc = 'best')

rmse = math.sqrt(mean_squared_error(TSLA_Test_Y.reshape(-1, 5), TSLA_prediction))
mape = np.mean(np.abs(TSLA_prediction - TSLA_Test_Y.reshape(-1, 5))/np.abs(TSLA_Test_Y.reshape(-1, 5)))
print(f'RMSE: {rmse}')
print(f'MAPE: {mape}')

"""#Google: Base de datos de acciones"""

GOOG.head()

GOOG.info()

# Change Dtype of Date column
GOOG["Date"] = pd.to_datetime(GOOG["Date"])

"""###Dividir los datos en conjunto de entrenamiento y prueba
    Periodo para partición de entrenamiento: 2015-01-02 - 2020-10-30

    Periodo para partición de testing: 2020-11-02 - 2021-02-26
"""

GOOG_Date = '2020-11-01'
GOOG_Train_X, GOOG_Train_Y, GOOG_Test_X, GOOG_Test_Y = Dataset(GOOG, GOOG_Date)

"""### Entrenamiento del modelo"""

GOOG_Model = Model()

GOOG_Model.compile(optimizer = tf.keras.optimizers.Adam(), loss = 'mse', metrics = tf.keras.metrics.RootMeanSquaredError())

GOOG_hist = GOOG_Model.fit(GOOG_Train_X, GOOG_Train_Y, epochs = 1000, validation_data = (GOOG_Test_X, GOOG_Test_Y), callbacks = [callback])

history_dict = GOOG_hist.history

loss = history_dict["loss"]
root_mean_squared_error = history_dict["root_mean_squared_error"]
val_loss = history_dict["val_loss"]
val_root_mean_squared_error = history_dict["val_root_mean_squared_error"]

epochs = range(1, len(loss) + 1)

fig, (ax1, ax2) = plt.subplots(1, 2)

fig.set_figheight(5)
fig.set_figwidth(15)

ax1.plot(epochs, loss, label = "Training Loss")
ax1.plot(epochs, val_loss, label = "Validation Loss")
ax1.set(xlabel = "Epochs", ylabel = "Loss")
ax1.legend()

ax2.plot(epochs, root_mean_squared_error, label = "Training Root Mean Squared Error")
ax2.plot(epochs, val_root_mean_squared_error, label = "Validation Root Mean Squared Error")
ax2.set(xlabel = "Epochs", ylabel = "Loss")
ax2.legend()

plt.show()

"""### Predecir el precio de cierre de las acciones de Google"""

GOOG_prediction = GOOG_Model.predict(GOOG_Test_X)

plt.figure(figsize=(10, 5))
plt.plot(GOOG['Date'][GOOG['Date'] < '2020-11-07'], GOOG['Adj. Close'][GOOG['Date'] < '2020-11-07'], label = 'Training')
plt.plot(GOOG['Date'][GOOG['Date'] >= '2020-11-07'], GOOG['Adj. Close'][GOOG['Date'] >= '2020-11-07'], label = 'Testing')
plt.plot(GOOG['Date'][GOOG['Date'] >= '2020-11-07'], GOOG_prediction.reshape(-1), label = 'Predictions')
plt.xlabel('Time')
plt.ylabel('Closing Price')
plt.legend(loc = 'best')

rmse = math.sqrt(mean_squared_error(GOOG_Test_Y.reshape(-1, 5), GOOG_prediction))
mape = np.mean(np.abs(GOOG_prediction - GOOG_Test_Y.reshape(-1, 5))/np.abs(GOOG_Test_Y.reshape(-1, 5)))
print(f'RMSE: {rmse}')
print(f'MAPE: {mape}')

"""#Microsoft: Base de datos de acciones"""

MSFT.head()

MSFT.info()

# Change Dtype of Date column
MSFT["Date"] = pd.to_datetime(MSFT["Date"])

"""###Dividir los datos en conjunto de entrenamiento y prueba
    Periodo para partición de entrenamiento: 2015-01-02 - 2020-09-30

    Periodo para partición de testing: 2020-10-01 - 2021-02-26
"""

MSFT_Date = '2020-10-01'
MSFT_Train_X, MSFT_Train_Y, MSFT_Test_X, MSFT_Test_Y = Dataset(MSFT, MSFT_Date)

"""### Entrenamiento del modelo"""

MSFT_Model = Model()

MSFT_Model.compile(optimizer = tf.keras.optimizers.Adam(), loss = 'mse', metrics = tf.keras.metrics.RootMeanSquaredError())

MSFT_hist = MSFT_Model.fit(MSFT_Train_X, MSFT_Train_Y, epochs = 1000, validation_data = (MSFT_Test_X, MSFT_Test_Y), callbacks=[callback])

history_dict = MSFT_hist.history

loss = history_dict["loss"]
root_mean_squared_error = history_dict["root_mean_squared_error"]
val_loss = history_dict["val_loss"]
val_root_mean_squared_error = history_dict["val_root_mean_squared_error"]

epochs = range(1, len(loss) + 1)

fig, (ax1, ax2) = plt.subplots(1, 2)

fig.set_figheight(5)
fig.set_figwidth(15)

ax1.plot(epochs, loss, label = "Training Loss")
ax1.plot(epochs, val_loss, label = "Validation Loss")
ax1.set(xlabel = "Epochs", ylabel = "Loss")
ax1.legend()

ax2.plot(epochs, root_mean_squared_error, label = "Training Root Mean Squared Error")
ax2.plot(epochs, val_root_mean_squared_error, label = "Validation Root Mean Squared Error")
ax2.set(xlabel = "Epochs", ylabel = "Loss")
ax2.legend()

plt.show()

"""### Predecir el precio de cierre de las acciones de Microsoft"""

MSFT_prediction = MSFT_Model.predict(MSFT_Test_X)

plt.figure(figsize=(10, 5))
plt.plot(MSFT['Date'][MSFT['Date'] < '2020-10-12'], MSFT['Adj. Close'][MSFT['Date'] < '2020-10-12'], label = 'Training')
plt.plot(MSFT['Date'][MSFT['Date'] >= '2020-10-09'], MSFT['Adj. Close'][MSFT['Date'] >= '2020-10-09'], label = 'Testing')
plt.plot(MSFT['Date'][MSFT['Date'] >= '2020-10-12'], MSFT_prediction.reshape(-1), label = 'Predictions')
plt.xlabel('Time')
plt.ylabel('Closing Price')
plt.legend(loc = 'best')

rmse = math.sqrt(mean_squared_error(MSFT_Test_Y.reshape(-1, 5), MSFT_prediction))
mape = np.mean(np.abs(MSFT_prediction - MSFT_Test_Y.reshape(-1, 5))/np.abs(MSFT_Test_Y.reshape(-1, 5)))
print(f'RMSE: {rmse}')
print(f'MAPE: {mape}')

"""#Amazon: Base de datos de acciones"""

AMZN.head()

AMZN.info()

# Change Dtype of Date column
AMZN["Date"] = pd.to_datetime(AMZN["Date"])

"""###Dividir los datos en conjunto de entrenamiento y prueba
    Periodo para partición de entrenamiento: 2015-01-02 - 2020-10-30

    Periodo para partición de testing: 2020-11-02 - 2021-02-26
"""

AMZN_Date = '2020-11-01'
AMZN_Train_X, AMZN_Train_Y, AMZN_Test_X, AMZN_Test_Y = Dataset(AMZN, AMZN_Date)

"""### Entrenamiento del modelo"""

AMZN_Model = Model()

AMZN_Model.compile(optimizer = tf.keras.optimizers.Adam(), loss = 'mse', metrics = tf.keras.metrics.RootMeanSquaredError())

AMZN_hist = AMZN_Model.fit(AMZN_Train_X, AMZN_Train_Y, epochs = 200, validation_data = (AMZN_Test_X, AMZN_Test_Y), callbacks=[callback])

history_dict = AMZN_hist.history

loss = history_dict["loss"]
root_mean_squared_error = history_dict["root_mean_squared_error"]
val_loss = history_dict["val_loss"]
val_root_mean_squared_error = history_dict["val_root_mean_squared_error"]

epochs = range(1, len(loss) + 1)

fig, (ax1, ax2) = plt.subplots(1, 2)

fig.set_figheight(5)
fig.set_figwidth(15)

ax1.plot(epochs, loss, label = "Training Loss")
ax1.plot(epochs, val_loss, label = "Validation Loss")
ax1.set(xlabel = "Epochs", ylabel = "Loss")
ax1.legend()

ax2.plot(epochs, root_mean_squared_error, label = "Training Root Mean Squared Error")
ax2.plot(epochs, val_root_mean_squared_error, label = "Validation Root Mean Squared Error")
ax2.set(xlabel = "Epochs", ylabel = "Loss")
ax2.legend()

plt.show()

"""### Predecir el precio de cierre de las acciones de Amazon"""

AMZN_prediction = AMZN_Model.predict(AMZN_Test_X)

plt.figure(figsize=(10, 5))
plt.plot(AMZN['Date'][AMZN['Date'] < '2020-11-07'], AMZN['Adj. Close'][AMZN['Date'] < '2020-11-07'], label = 'Training')
plt.plot(AMZN['Date'][AMZN['Date'] >= '2020-11-07'], AMZN['Adj. Close'][AMZN['Date'] >= '2020-11-07'], label = 'Testing')
plt.plot(AMZN['Date'][AMZN['Date'] >= '2020-11-07'], AMZN_prediction.reshape(-1), label = 'Predictions')
plt.xlabel('Time')
plt.ylabel('Closing Price')
plt.legend(loc = 'best')

rmse = math.sqrt(mean_squared_error(AMZN_Test_Y.reshape(-1, 5), AMZN_prediction))
mape = np.mean(np.abs(AMZN_prediction - AMZN_Test_Y.reshape(-1, 5))/np.abs(AMZN_Test_Y.reshape(-1, 5)))
print(f'RMSE: {rmse}')
print(f'MAPE: {mape}')

"""# Codigos extras para analisis del informe

# 1. Análisis de Métricas de Rendimiento (RMSE y MAPE)
"""

def evaluate_performance(test_y, predicted_y, company_name):
    rmse = math.sqrt(mean_squared_error(test_y.reshape(-1, 5), predicted_y))
    mape = np.mean(np.abs(predicted_y - test_y.reshape(-1, 5)) / np.abs(test_y.reshape(-1, 5))) * 100
    print(f'{company_name} - RMSE: {rmse}, MAPE: {mape}%')

# Ejecuta esta función para cada compañía
evaluate_performance(AAPL_Test_Y, AAPL_prediction, "Apple")
evaluate_performance(TSLA_Test_Y, TSLA_prediction, "Tesla")
evaluate_performance(GOOG_Test_Y, GOOG_prediction, "Google")
evaluate_performance(MSFT_Test_Y, MSFT_prediction, "Microsoft")
evaluate_performance(AMZN_Test_Y, AMZN_prediction, "Amazon")

"""# 2. Resumen del Entrenamiento del Modelo"""

def summarize_training(history, company_name):
    final_epoch = len(history.history['loss'])
    final_loss = history.history['loss'][-1]
    final_val_loss = history.history['val_loss'][-1]
    final_rmse = history.history['root_mean_squared_error'][-1]
    final_val_rmse = history.history['val_root_mean_squared_error'][-1]

    print(f'{company_name} - Final Epoch: {final_epoch}')
    print(f'{company_name} - Final Training Loss: {final_loss}')
    print(f'{company_name} - Final Validation Loss: {final_val_loss}')
    print(f'{company_name} - Final Training RMSE: {final_rmse}')
    print(f'{company_name} - Final Validation RMSE: {final_val_rmse}')

# Ejecuta esta función para cada compañía
summarize_training(AAPL_hist, "Apple")
summarize_training(TSLA_hist, "Tesla")
summarize_training(GOOG_hist, "Google")
summarize_training(MSFT_hist, "Microsoft")
summarize_training(AMZN_hist, "Amazon")

"""# 3. Análisis de Tendencias de Pérdida y RMSE a lo Largo del Entrenamiento"""

def summarize_trends(history, company_name):
    training_loss = history.history['loss']
    validation_loss = history.history['val_loss']
    training_rmse = history.history['root_mean_squared_error']
    validation_rmse = history.history['val_root_mean_squared_error']

    print(f'{company_name} - Training Loss: Start {training_loss[0]}, End {training_loss[-1]}, Max {max(training_loss)}, Min {min(training_loss)}, Mean {np.mean(training_loss)}')
    print(f'{company_name} - Validation Loss: Start {validation_loss[0]}, End {validation_loss[-1]}, Max {max(validation_loss)}, Min {min(validation_loss)}, Mean {np.mean(validation_loss)}')
    print(f'{company_name} - Training RMSE: Start {training_rmse[0]}, End {training_rmse[-1]}, Max {max(training_rmse)}, Min {min(training_rmse)}, Mean {np.mean(training_rmse)}')
    print(f'{company_name} - Validation RMSE: Start {validation_rmse[0]}, End {validation_rmse[-1]}, Max {max(validation_rmse)}, Min {min(validation_rmse)}, Mean {np.mean(validation_rmse)}')

# Ejecuta esta función para cada compañía
summarize_trends(AAPL_hist, "Apple")
summarize_trends(TSLA_hist, "Tesla")
summarize_trends(GOOG_hist, "Google")
summarize_trends(MSFT_hist, "Microsoft")
summarize_trends(AMZN_hist, "Amazon")